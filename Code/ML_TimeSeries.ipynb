{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from: https://www.kdnuggets.com/2018/11/keras-long-short-term-memory-lstm-model-predict-stock-prices.html\n",
    "\n",
    "Method:\n",
    "* Uses the historical dataset to learn, and then the a subset of the newer dataset to make prediction. This allows us to actually compare the predictions to what the values really were. The subset range can be modified at will.\n",
    "\n",
    "\n",
    "Findings:\n",
    "* As opposed to statistical time series LSTM does well on daily basis, but fails on monthly/weekly data. Likely because it needs lots of data to learn anything. Can be an interesting point to make, that LSTM is good to model daily data and statistical time series is better for monthly/weekly.\n",
    "* Does really well compared to the standard ML approaches, however, accuracy not the best for all pollutants (try for more epochs maybe?)\n",
    "\n",
    "Graph info:\n",
    "* Graph #1 = predicted values vs actual values in the new 'live' dataset\n",
    "* Graph #2 = historical data with the predictions appended at the end\n",
    "* Graph #3 = historical data + new values from the 'live' dataset merged together, along with predicted values on top for comparison (this one needs updating as the predictions should overlap the new data at the end of axis, not at the start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn import linear_model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/BathHistoricalAirSensorData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean so the data is the same as EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Null Values % of data after cleanup *\n",
      "nitrogen_monoxide (NO) ppb        0.0\n",
      "nitrogen_dioxide (No2) ppb        0.0\n",
      "carbon_monoxide (CO) ppm          0.0\n",
      "aerosol_particles (pm10) µg/m3    0.0\n",
      "dtype: float64 \n",
      "\n",
      "\n",
      "* Shape *\n",
      "63896\n"
     ]
    }
   ],
   "source": [
    "# drop irrelevant columns\n",
    "df = df.drop(['sensor_location_name', 'id', 'sensor_location_slug', 'sensor_location'], axis=1)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={'nox'   : 'nitrogen_oxides (No2 + NO) ppb',\n",
    "                        'no'    : 'nitrogen_monoxide (NO) ppb',\n",
    "                        'no2'   : 'nitrogen_dioxide (No2) ppb',\n",
    "                        'co'    : 'carbon_monoxide (CO) ppm',\n",
    "                        'pm10'  : 'aerosol_particles (pm10) µg/m3',\n",
    "                        'o3'    : 'ozone (o3) ppb'})\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['nitrogen_oxides (No2 + NO) ppb'])\n",
    "\n",
    "df = df.drop(['ozone (o3) ppb'], axis=1)\n",
    "\n",
    "pollutants = ['nitrogen_monoxide (NO) ppb',\n",
    "              'nitrogen_dioxide (No2) ppb',\n",
    "             'carbon_monoxide (CO) ppm',\n",
    "             'aerosol_particles (pm10) µg/m3']\n",
    "\n",
    "# Set index as time\n",
    "df['datetime'] = pd.to_datetime(df.datetime)\n",
    "df = df.set_index('datetime')\n",
    "df = df.sort_index()\n",
    "#df = df.resample('W-MON').mean()\n",
    "\n",
    "for p in pollutants:\n",
    "    if df[p].isna().sum() > 0:\n",
    "        df[p].interpolate(method='time', inplace=True)\n",
    "        \n",
    "df = df.dropna(subset=['aerosol_particles (pm10) µg/m3'])\n",
    "\n",
    "df = df.drop(['nitrogen_oxides (No2 + NO) ppb'], axis=1)\n",
    "        \n",
    "print('\\n* Null Values % of data after cleanup *')       \n",
    "print(df.isna().sum()/len(df), '\\n')\n",
    "print('\\n* Shape *')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the newer (not historical) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Null Values % of data after cleanup *\n",
      "nitrogen_monoxide (NO) ppb        0.0\n",
      "nitrogen_dioxide (No2) ppb        0.0\n",
      "carbon_monoxide (CO) ppm          0.0\n",
      "aerosol_particles (pm10) µg/m3    0.0\n",
      "dtype: float64 \n",
      "\n",
      "\n",
      "* Shape *\n",
      "94071\n",
      "\n",
      "* Shape of the selected range *\n",
      "10212\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_csv('data/BathAirSensorData.csv')\n",
    "\n",
    "# drop irrelevant columns\n",
    "df_new = df_new.drop(['sensor_location_name', 'id', 'sensor_location_slug', 'sensor_location'], axis=1)\n",
    "\n",
    "# rename columns\n",
    "df_new = df_new.rename(columns={'nox'   : 'nitrogen_oxides (No2 + NO) ppb',\n",
    "                        'no'    : 'nitrogen_monoxide (NO) ppb',\n",
    "                        'no2'   : 'nitrogen_dioxide (No2) ppb',\n",
    "                        'co'    : 'carbon_monoxide (CO) ppm',\n",
    "                        'pm10'  : 'aerosol_particles (pm10) µg/m3',\n",
    "                        'o3'    : 'ozone (o3) ppb'})\n",
    "\n",
    "\n",
    "df_new = df_new.dropna(subset=['nitrogen_oxides (No2 + NO) ppb'])\n",
    "\n",
    "df_new = df_new.drop(['ozone (o3) ppb'], axis=1)\n",
    "\n",
    "pollutants = ['nitrogen_monoxide (NO) ppb',\n",
    "              'nitrogen_dioxide (No2) ppb',\n",
    "             'carbon_monoxide (CO) ppm',\n",
    "             'aerosol_particles (pm10) µg/m3']\n",
    "\n",
    "# Set index as time\n",
    "df_new['datetime'] = pd.to_datetime(df_new.datetime)\n",
    "df_new = df_new.set_index('datetime')\n",
    "df_new = df_new.sort_index()\n",
    "#df_new = df_new.resample('W-MON').mean()\n",
    "\n",
    "for p in pollutants:\n",
    "    if df_new[p].isna().sum() > 0:\n",
    "        df_new[p].interpolate(method='time', inplace=True)\n",
    "        \n",
    "df_new = df_new.dropna(subset=['aerosol_particles (pm10) µg/m3'])\n",
    "\n",
    "df_new = df_new.drop(['nitrogen_oxides (No2 + NO) ppb'], axis=1)\n",
    "        \n",
    "print('\\n* Null Values % of data after cleanup *')       \n",
    "print(df_new.isna().sum()/len(df_new), '\\n')\n",
    "print('\\n* Shape *')\n",
    "print(df_new.shape[0])\n",
    "\n",
    "# Selecting range to which the model will try and predict\n",
    "df_new = df_new.loc['2014-07-08 17:00:00+00:00 ':'2015-01-01 00:00:00+00:00 ']\n",
    "print('\\n* Shape of the selected range *')\n",
    "print(df_new.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(x,y,epochs):\n",
    "    regressor = Sequential()\n",
    "    \n",
    "    # lstm\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    # output layer\n",
    "    regressor.add(Dense(units = 1))\n",
    "    \n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    # fit\n",
    "    regressor.fit(x, y, epochs = epochs, batch_size = 32, verbose=2)\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, preds, part, invert, path=None, save=True,):\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    \n",
    "    \n",
    "    if(part == False):\n",
    "        labels = [2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015]   \n",
    "\n",
    "    else:\n",
    "        labels = ['2014-07','2014-08','2014-09','2014-10','2014-11','2014-12','2015-01']         \n",
    "\n",
    "    if(invert == False):\n",
    "        ax.plot(data, label='Data', color='blue')            \n",
    "        ax.plot(preds, label='Predictions', color='orange') \n",
    "    else:\n",
    "        ax.plot(preds, label='Predictions', color='orange')\n",
    "        ax.plot(data, label='Data', color='blue')  \n",
    "    \n",
    "    # Make it pretty\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Sensor Value')    \n",
    "    ax.set_title(('LSTM of: {} on daily basis predictions for {}'.format(pollutants[pollutant], '2014-07-08 - 2015-01-01')), size=16)  \n",
    "    ax.set_xticks(np.linspace(0,(data.shape[0]),len(labels)))\n",
    "        \n",
    "    ax.set_xticklabels(labels)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Maybe save?\n",
    "    if save: plt.savefig(path)\n",
    "    \n",
    "    plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Train on 63836 samples\n",
      "Epoch 1/3\n",
      "63836/63836 - 131s - loss: 0.0047\n",
      "Epoch 2/3\n",
      "63836/63836 - 142s - loss: 0.0043\n",
      "Epoch 3/3\n",
      "63836/63836 - 365s - loss: 0.0043\n",
      "Time to predict\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a58239b66538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m          \u001b[0mpredicted_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m          \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m          path='graphs/LSTM1_{}.PNG'.format(pollutants[p].split()[0]))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Plot entire dataset + predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pollutants = ['nitrogen_monoxide (NO) ppb', 'nitrogen_dioxide (No2) ppb', \n",
    "              'carbon_monoxide (CO) ppm', 'aerosol_particles (pm10) µg/m3']\n",
    "\n",
    "# Train\n",
    "for pollutant in [0,1,2,3]:\n",
    "    \n",
    "    # Select column with the right pollutant\n",
    "    if pollutant != 3:\n",
    "        training_set = df.iloc[:, pollutant:pollutant+1].values  \n",
    "        real_vals = df_new.iloc[:, pollutant:pollutant+1].values   \n",
    "    else: \n",
    "        training_set = df.iloc[:,3:].values \n",
    "        real_vals = df_new.iloc[:, 3:].values        \n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Feature Scaling\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "    # Sequences of 60 for the training sets\n",
    "    for i in range(60, training_set_scaled.shape[0]):\n",
    "        X_train.append(training_set_scaled[i-60:i, 0])\n",
    "        y_train.append(training_set_scaled[i, 0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # Reshaping\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    # Fit model\n",
    "    print('Fitting the model')\n",
    "    regressor = lstm(X_train, y_train, epochs=3)\n",
    "\n",
    "    dataset_total = pd.concat((df['nitrogen_monoxide (NO) ppb'], df_new['nitrogen_monoxide (NO) ppb']), axis = 0)\n",
    "    inputs = dataset_total[len(dataset_total) - len(df_new) - 60:].values\n",
    "\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs = sc.transform(inputs)\n",
    "    \n",
    "    # Create the test set\n",
    "    X_test = []\n",
    "    for i in range(60, inputs.shape[0]):\n",
    "        X_test.append(inputs[i-60:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    print('Time to predict')\n",
    "    # Predict\n",
    "    predicted_vals = regressor.predict(X_test)\n",
    "    \n",
    "    # Revert values back to normal\n",
    "    predicted_vals  = sc.inverse_transform(predicted_vals)\n",
    "\n",
    "    merged = np.concatenate([training_set, real_vals])\n",
    "    \n",
    "    # Plot preds vs real values\n",
    "    plot(real_vals, \n",
    "         predicted_vals,\n",
    "         True, False,\n",
    "         path='graphs/LSTM1_{}.PNG'.format(pollutants[p].split()[0]))\n",
    "    \n",
    "    # Plot entire dataset + predictions    \n",
    "    plot(training_set,\n",
    "         np.append(training_set, predicted_vals),\n",
    "         False, True,\n",
    "         path='graphs/LSTM2_{}.PNG'.format(pollutants[pollutant].split()[0]))    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
